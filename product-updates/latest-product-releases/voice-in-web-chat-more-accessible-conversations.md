---
description: Released in June 2025
---

# Voice in Web Chat: More Accessible Conversations

## **A more natural, inclusive way to engage with your virtual assistant**

Weâ€™ve just added **native voice capabilities to the indigo.ai web chat widget**, making conversations more human-like, accessible, and intuitive than ever.&#x20;

**Users can now listen to messages or speak instead of typing**, all directly within the widget.

Voice has long been available as a [dedicated channel](../../getting-started/communication-channels/voice.md) (for phone-based virtual assistants), and now itâ€™s available in your web chat too.

This update unlocks a powerful layer of **accessibility and usability**: users with visual impairments, reading difficulties, or limited mobility, as well as those simply on the go, can now engage with your AI Agent using their voice.

## ğŸ™ï¸ Speak Instead of Typing

<figure><img src="../../.gitbook/assets/Screenshot 2025-07-07 alle 11.51.52.png" alt=""><figcaption></figcaption></figure>

Users can now **record a voice message right from the typebar in normal chat mode**. Instead of sending the audio directly, the system **transcribes the message and places the resulting text in the typebar, ready for editing or immediate sending**.

This makes it easier and faster to communicate, especially for users who prefer speaking over typing, or those using mobile devices.

## ğŸ§ Listen to the Botâ€™s Messages

<figure><img src="../../.gitbook/assets/Screenshot 2025-07-07 alle 11.52.23.png" alt=""><figcaption></figcaption></figure>

Users can now listen to any message from the virtual assistant with a single tap. A dedicated speaker icon appears next to every message: when clicked, it **reads the virtual assistants' message aloud using the selected voice and provider** (e.g., ElevenLabs).&#x20;

* A quick loading indicator appears before the playback starts
* Users can pause or stop playback at any time
* The voice used can be customized in the platform settings

This makes content more accessible and creates a more natural interaction flow, especially in mobile and multitasking environments.

## ğŸ“ Call Mode (Coming Soon)

<figure><img src="../../.gitbook/assets/Screenshot 2025-07-07 alle 11.45.42.png" alt="" width="313"><figcaption></figcaption></figure>

We are working on a feature that will allow users to start a real-time **voice call with your AI Agent**, right from the web chat. With this feature, the chat transforms into a fully voice-based experience.

This will open up an entirely new way for customers to engage, especially for use cases like support, onboarding, or conversational services.

{% hint style="info" %}
Curious about the upcoming Call Mode? If you'd like a preview demo of the feature before release, feel free to reach out to our [Customer Success team](../../need-help/our-customer-success-team.md).
{% endhint %}

### ğŸ”§ How to Enable

You can activate both **message listening** and **voice input** directly from your workspace settings under:\
[**Settings â†’ Web Chat â†’ Voice**](../../build-your-ai-agents/configure-and-install-the-web-chat.md#voice).

<figure><img src="../../.gitbook/assets/Screenshot 2025-07-07 alle 11.34.16.png" alt=""><figcaption></figcaption></figure>

You can:

* Choose a voice provider (e.g., ElevenLabs)
* Select a preferred voice
* Enable listening and/or voice input modes.&#x20;

These new voice features are now available to all workspaces. No special API or configuration required: just activate them in your widget settings.
